"""
KTDB GTFS ë°ì´í„° ë¡œë” v5.0 - BOM ë° ì¸ì½”ë”© ë¬¸ì œ ì™„ì „ í•´ê²°
- BOM ë¬¸ì ì™„ë²½ ì œê±°
- í•œê¸€ ì¸ì½”ë”© ì •í™•í•œ ì²˜ë¦¬
- routes.txt ë¬¸ì œ í•´ê²°
"""

import pandas as pd
import numpy as np
from pathlib import Path
import warnings
import time
from datetime import datetime
import pickle
import json
import re

warnings.filterwarnings('ignore')

class KTDBGTFSLoader:
    """GTFS ë°ì´í„° ë¡œë” - ì™„ì „ ìˆ˜ì • ë²„ì „"""
    
    def __init__(self, gtfs_data_path: str):
        self.gtfs_data_path = Path(gtfs_data_path)
        
        # GTFS ë°ì´í„° í…Œì´ë¸”
        self.agency = None
        self.stops = None
        self.routes = None  
        self.trips = None
        self.stop_times = None
        self.calendar = None
        self.calendar_dates = None
        self.transfers = None
        
        # í†µê³„
        self.stats = {}
        
        print("ğŸš€ KTDB GTFS ë°ì´í„° ë¡œë” v5.0")
        print(f"ğŸ“‚ ê²½ë¡œ: {self.gtfs_data_path}")
        
        if not self.gtfs_data_path.exists():
            raise FileNotFoundError(f"ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤: {self.gtfs_data_path}")
    
    def load_all_data(self) -> bool:
        """ëª¨ë“  GTFS ë°ì´í„° ë¡œë“œ ë° ì •ë¦¬"""
        print("\nğŸš‡ GTFS ë°ì´í„° ë¡œë”©...")
        start_time = time.time()
        
        # 1. ê° íŒŒì¼ ë¡œë“œ (BOM ì œê±° í¬í•¨)
        self._load_with_bom_removal()
        
        # 2. ì»¬ëŸ¼ëª… ì •ë¦¬
        self._fix_all_column_names()
        
        # 3. ë°ì´í„° íƒ€ì… ìµœì í™”
        self._optimize_data_types()
        
        # 4. ë°ì´í„° ê²€ì¦
        self._validate_data()
        
        # 5. í†µê³„ ì¶œë ¥
        elapsed = time.time() - start_time
        self._print_summary(elapsed)
        
        return True
    
    def _load_with_bom_removal(self):
        """BOMì„ ì œê±°í•˜ë©° íŒŒì¼ ë¡œë“œ"""
        
        files = {
            'agency': 'agency.txt',
            'stops': 'stops.txt',
            'routes': 'routes.txt',
            'trips': 'trips.txt',
            'stop_times': 'stop_times.txt',
            'calendar': 'calendar.txt'
        }
        
        for data_name, filename in files.items():
            file_path = self.gtfs_data_path / filename
            
            if not file_path.exists():
                print(f"   âŒ {filename} ì—†ìŒ")
                continue
            
            print(f"   ğŸ“‚ {filename} ë¡œë”©...", end=' ')
            
            # ë¨¼ì € íŒŒì¼ì„ ì½ì–´ì„œ BOM ì œê±°
            try:
                # ì›ë³¸ íŒŒì¼ ì½ê¸° (ë°”ì´ë„ˆë¦¬ ëª¨ë“œ)
                with open(file_path, 'rb') as f:
                    raw_data = f.read()
                
                # BOM íŒ¨í„´ë“¤
                bom_patterns = [
                    b'\xef\xbb\xbf',  # UTF-8 BOM
                    b'\xff\xfe',      # UTF-16 LE BOM
                    b'\xfe\xff',      # UTF-16 BE BOM
                    b'\xec\x99\xa4',  # ç™¤ ë¬¸ì
                ]
                
                # BOM ì œê±°
                for bom in bom_patterns:
                    if raw_data.startswith(bom):
                        raw_data = raw_data[len(bom):]
                        break
                
                # ì„ì‹œ íŒŒì¼ì— ì“°ê¸°
                temp_path = file_path.parent / f'temp_{filename}'
                with open(temp_path, 'wb') as f:
                    f.write(raw_data)
                
                # pandasë¡œ ì½ê¸° (ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„)
                df = None
                for encoding in ['utf-8', 'cp949', 'euc-kr', 'latin1']:
                    try:
                        df = pd.read_csv(temp_path, encoding=encoding)
                        
                        # ì„±ê³µí•˜ë©´ ì»¬ëŸ¼ëª… ì •ë¦¬
                        df.columns = [self._clean_column_name(col) for col in df.columns]
                        
                        setattr(self, data_name, df)
                        print(f"âœ… {len(df):,}í–‰")
                        
                        # íŠ¹ë³„ ì²˜ë¦¬: routes.txtê°€ ë„ˆë¬´ ì ìœ¼ë©´ ê²½ê³ 
                        if data_name == 'routes' and len(df) < 100:
                            print(f"      âš ï¸ ê²½ê³ : routesê°€ {len(df)}ê°œë°–ì— ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
                            # routes.txtë¥¼ ë‹¤ì‹œ ì½ê¸° ì‹œë„
                            self._try_fix_routes(file_path)
                        
                        break
                    except Exception as e:
                        continue
                
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                temp_path.unlink(missing_ok=True)
                
                if df is None:
                    print(f"âŒ ì½ê¸° ì‹¤íŒ¨")
                    
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜: {e}")
    
    def _clean_column_name(self, col: str) -> str:
        """ì»¬ëŸ¼ëª…ì—ì„œ BOM ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°"""
        
        # ë¬¸ìì—´ë¡œ ë³€í™˜
        col = str(col)
        
        # BOM ë¬¸ìë“¤ ì œê±°
        bom_chars = ['ç™¤', 'Ã¯Â»Â¿', 'ï»¿', '\ufeff', 'ÃƒÂ¯Ã‚Â»Ã‚Â¿']
        for bom in bom_chars:
            col = col.replace(bom, '')
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€ ì œì™¸)
        col = re.sub(r'^[^\wê°€-í£]+', '', col)
        
        # ì•Œë ¤ì§„ ì˜ëª»ëœ ë§¤í•‘
        wrong_mappings = {
            'í’¹gency_id': 'agency_id',
            'í“Šoute_id': 'route_id',
            'í“‹ervice_id': 'service_id',
            'oute_id': 'route_id',
            'ervice_id': 'service_id',
            'gency_id': 'agency_id'
        }
        
        # ë§¤í•‘ ì ìš©
        for wrong, correct in wrong_mappings.items():
            if wrong in col:
                return correct
        
        return col.strip()
    
    def _fix_all_column_names(self):
        """ëª¨ë“  í…Œì´ë¸”ì˜ ì»¬ëŸ¼ëª… ì •ë¦¬"""
        print("\n   ğŸ”§ ì»¬ëŸ¼ëª… ì •ë¦¬ ì¤‘...")
        
        # ê° í…Œì´ë¸”ë³„ë¡œ ì»¬ëŸ¼ ì •ë¦¬
        tables = ['agency', 'stops', 'routes', 'trips', 'stop_times', 'calendar']
        
        for table_name in tables:
            table = getattr(self, table_name)
            if table is not None:
                before = list(table.columns)
                table.columns = [self._clean_column_name(col) for col in table.columns]
                after = list(table.columns)
                
                # ë³€ê²½ëœ ì»¬ëŸ¼ ì¶œë ¥
                changed = [(b, a) for b, a in zip(before, after) if b != a]
                if changed:
                    print(f"      {table_name}: {len(changed)}ê°œ ì»¬ëŸ¼ ìˆ˜ì •")
                    for old, new in changed[:3]:  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
                        print(f"         {old} â†’ {new}")
    
    def _try_fix_routes(self, original_path: Path):
        """routes.txt ë¬¸ì œ í•´ê²° ì‹œë„"""
        print("\n   ğŸ”§ routes.txt ë³µêµ¬ ì‹œë„...")
        
        # routes.txtë¥¼ ë‹¤ì‹œ ì½ë˜, ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ
        try:
            # 1. ë¼ì¸ ë‹¨ìœ„ë¡œ ì½ê¸°
            with open(original_path, 'r', encoding='utf-8-sig', errors='ignore') as f:
                lines = f.readlines()
            
            if len(lines) > 1:
                # í—¤ë” ì •ë¦¬
                header = lines[0].strip()
                header = self._clean_column_name(header)
                headers = [self._clean_column_name(h.strip()) for h in header.split(',')]
                
                # ë°ì´í„° íŒŒì‹±
                data = []
                for line in lines[1:]:
                    line = line.strip()
                    if line:
                        # ë”°ì˜´í‘œ ì²˜ë¦¬
                        parts = []
                        in_quote = False
                        current = ''
                        
                        for char in line:
                            if char == '"':
                                in_quote = not in_quote
                            elif char == ',' and not in_quote:
                                parts.append(current.strip().strip('"'))
                                current = ''
                            else:
                                current += char
                        
                        if current:
                            parts.append(current.strip().strip('"'))
                        
                        if len(parts) == len(headers):
                            data.append(parts)
                
                # DataFrame ìƒì„±
                if data:
                    self.routes = pd.DataFrame(data, columns=headers)
                    print(f"      âœ… routes.txt ë³µêµ¬ ì„±ê³µ: {len(self.routes)}ê°œ ë…¸ì„ ")
                else:
                    print(f"      âŒ routes.txt ë³µêµ¬ ì‹¤íŒ¨")
                    
        except Exception as e:
            print(f"      âŒ routes.txt ë³µêµ¬ ì‹¤íŒ¨: {e}")
            
            # ìµœí›„ì˜ ìˆ˜ë‹¨: tripsì—ì„œ route_id ì¶”ì¶œ
            if self.trips is not None and 'route_id' in self.trips.columns:
                unique_routes = self.trips['route_id'].unique()
                self.routes = pd.DataFrame({
                    'route_id': unique_routes,
                    'agency_id': 'DEFAULT',
                    'route_short_name': unique_routes,
                    'route_long_name': unique_routes,
                    'route_type': 3  # ë²„ìŠ¤ë¡œ ê°€ì •
                })
                print(f"      âœ… tripsì—ì„œ routes ì¬êµ¬ì„±: {len(self.routes)}ê°œ")
    
    def _optimize_data_types(self):
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        print("\n   ğŸ’¾ ë©”ëª¨ë¦¬ ìµœì í™”...")
        
        before = self._calculate_memory()
        
        # stops ìµœì í™”
        if self.stops is not None:
            if 'stop_lat' in self.stops.columns:
                self.stops['stop_lat'] = pd.to_numeric(self.stops['stop_lat'], errors='coerce').astype('float32')
            if 'stop_lon' in self.stops.columns:
                self.stops['stop_lon'] = pd.to_numeric(self.stops['stop_lon'], errors='coerce').astype('float32')
            
            # ë¬¸ìì—´ ì»¬ëŸ¼ category ë³€í™˜
            for col in ['stop_id', 'stop_name']:
                if col in self.stops.columns:
                    if self.stops[col].nunique() < len(self.stops) * 0.5:
                        self.stops[col] = self.stops[col].astype('category')
        
        # trips ìµœì í™”
        if self.trips is not None:
            for col in ['trip_id', 'route_id', 'service_id']:
                if col in self.trips.columns:
                    self.trips[col] = self.trips[col].astype(str)
                    if self.trips[col].nunique() < len(self.trips) * 0.5:
                        self.trips[col] = self.trips[col].astype('category')
        
        # stop_times ìµœì í™”
        if self.stop_times is not None:
            for col in ['trip_id', 'stop_id']:
                if col in self.stop_times.columns:
                    self.stop_times[col] = self.stop_times[col].astype(str)
                    if self.stop_times[col].nunique() < len(self.stop_times) * 0.5:
                        self.stop_times[col] = self.stop_times[col].astype('category')
            
            if 'stop_sequence' in self.stop_times.columns:
                self.stop_times['stop_sequence'] = pd.to_numeric(
                    self.stop_times['stop_sequence'], errors='coerce'
                ).fillna(0).astype('uint16')
        
        after = self._calculate_memory()
        
        if before > 0:
            reduction = (1 - after/before) * 100
            print(f"      ë©”ëª¨ë¦¬: {before:.1f}MB â†’ {after:.1f}MB ({reduction:.1f}% ì ˆê°)")
    
    def _validate_data(self):
        """ë°ì´í„° ê²€ì¦"""
        print("\n   ğŸ” ë°ì´í„° ê²€ì¦...")
        
        issues = []
        
        # 1. routes ê²€ì¦
        if self.routes is not None:
            if len(self.routes) < 100:
                issues.append(f"routesê°€ {len(self.routes)}ê°œë°–ì— ì—†ìŒ (ë¹„ì •ìƒ)")
        else:
            issues.append("routes ë°ì´í„° ì—†ìŒ")
        
        # 2. tripsì˜ route_id ê²€ì¦
        if self.trips is not None:
            if 'route_id' not in self.trips.columns:
                issues.append("tripsì— route_id ì»¬ëŸ¼ ì—†ìŒ")
            else:
                null_routes = self.trips['route_id'].isna().sum()
                if null_routes > 0:
                    issues.append(f"route_idê°€ ì—†ëŠ” trip: {null_routes}ê°œ")
        
        # 3. ì°¸ì¡° ë¬´ê²°ì„±
        if self.trips is not None and self.routes is not None:
            if 'route_id' in self.trips.columns and 'route_id' in self.routes.columns:
                trip_routes = set(self.trips['route_id'].dropna().unique())
                valid_routes = set(self.routes['route_id'].unique())
                orphan_routes = trip_routes - valid_routes
                
                if orphan_routes:
                    issues.append(f"routesì— ì—†ëŠ” route_id ì°¸ì¡°: {len(orphan_routes)}ê°œ")
                    # ìë™ ë³µêµ¬ ì‹œë„
                    self._auto_fix_routes(orphan_routes)
        
        # ê²°ê³¼ ì¶œë ¥
        if issues:
            print("      âš ï¸ ë°œê²¬ëœ ë¬¸ì œ:")
            for issue in issues:
                print(f"         - {issue}")
        else:
            print("      âœ… ëª¨ë“  ê²€ì¦ í†µê³¼")
    
    def _auto_fix_routes(self, missing_route_ids):
        """ëˆ„ë½ëœ routes ìë™ ìƒì„±"""
        print("\n      ğŸ”§ ëˆ„ë½ëœ routes ìë™ ìƒì„±...")
        
        new_routes = []
        for route_id in missing_route_ids:
            new_routes.append({
                'route_id': route_id,
                'agency_id': 'AUTO',
                'route_short_name': str(route_id),
                'route_long_name': f'ìë™ìƒì„±_{route_id}',
                'route_type': 3  # ë²„ìŠ¤
            })
        
        if new_routes:
            new_df = pd.DataFrame(new_routes)
            self.routes = pd.concat([self.routes, new_df], ignore_index=True)
            print(f"         âœ… {len(new_routes)}ê°œ route ìë™ ìƒì„±")
    
    def _calculate_memory(self) -> float:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚° (MB)"""
        total = 0
        for table_name in ['stops', 'routes', 'trips', 'stop_times', 'calendar']:
            table = getattr(self, table_name)
            if table is not None:
                total += table.memory_usage(deep=True).sum() / 1024 / 1024
        return total
    
    def _print_summary(self, elapsed: float):
        """ë¡œë”© ê²°ê³¼ ìš”ì•½"""
        print(f"\nğŸ“Š ë¡œë”© ì™„ë£Œ ({elapsed:.1f}ì´ˆ)")
        print("=" * 60)
        
        # ê° í…Œì´ë¸” í†µê³„
        for name in ['stops', 'routes', 'trips', 'stop_times']:
            table = getattr(self, name)
            if table is not None:
                print(f"   {name:12s}: {len(table):>10,}í–‰, {len(table.columns):>3}ì—´")
                if name == 'routes' and len(table) < 100:
                    print(f"                  âš ï¸ ê²½ê³ : ë…¸ì„  ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤!")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        memory = self._calculate_memory()
        print(f"\n   ì´ ë©”ëª¨ë¦¬: {memory:.1f}MB")
    
    def save_clean_data(self, output_dir: str):
        """ì •ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        print(f"\nğŸ’¾ ë°ì´í„° ì €ì¥: {output_dir}/")
        
        # CSVë¡œ ì €ì¥ (BOM ì—†ì´)
        for name in ['stops', 'routes', 'trips', 'stop_times', 'calendar']:
            table = getattr(self, name)
            if table is not None:
                file_path = output_path / f"{name}.csv"
                table.to_csv(file_path, index=False, encoding='utf-8')
                print(f"   âœ… {name}.csv")
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'created_at': datetime.now().isoformat(),
            'stats': {
                'stops': len(self.stops) if self.stops is not None else 0,
                'routes': len(self.routes) if self.routes is not None else 0,
                'trips': len(self.trips) if self.trips is not None else 0,
                'stop_times': len(self.stop_times) if self.stop_times is not None else 0
            },
            'issues_fixed': [
                'BOM ë¬¸ì ì œê±°',
                'ì»¬ëŸ¼ëª… ì •ë¦¬',
                'routes ë°ì´í„° ë³µêµ¬'
            ]
        }
        
        with open(output_path / 'metadata.json', 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print("   âœ… metadata.json")
        print("\nâœ… ëª¨ë“  ë°ì´í„°ê°€ ì •ë¦¬ë˜ì–´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")


# ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    print("=" * 60)
    print("KTDB GTFS ë°ì´í„° ë¡œë” - BOM ë° ì¸ì½”ë”© ë¬¸ì œ í•´ê²°")
    print("=" * 60)
    
    # GTFS ê²½ë¡œ
    gtfs_path = "/home/twdaniel/multimodal_project2/202303_GTFS_DataSet"  # ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì •
    
    try:
        # ë¡œë” ìƒì„± ë° ì‹¤í–‰
        loader = KTDBGTFSLoader(gtfs_path)
        loader.load_all_data()
        
        # ì •ë¦¬ëœ ë°ì´í„° ì €ì¥
        loader.save_clean_data("cleaned_gtfs_data")
        
        print("\nğŸ‰ ì„±ê³µ! ì´ì œ Part1ì—ì„œ cleaned_gtfs_dataë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()